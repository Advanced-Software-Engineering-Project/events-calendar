# Component 2: Scraper

### Info
*Files:
```
/scraper/events_scraper.py
/scraper/groups_scraper.py
/scraper/data_cleaner.py
/scraper/data_importer.py
```
* Reader: Ian
* Recorder: Peng

### How it works
The scraper gets the events info starting from the current datetime and imports information to database. 

### Additional Problems
* Refresh app token every 60 days automatically
    * The facebook data access token depends on a self-made app based on facebook developer tools. The token of a facebook user functions as a key to access the events data. But the token itself is generated by facebook developer tool every around 60 days. The scraper needs to update the access token if it keeps running more than 60 days.
* (Fixed) External package as environments
    * Update the requirements.txt to satisfy the scraper dependencies.
* (Fixed) Handle duplicate key exceptions:
    * Try and except sqlalchemy.exc.IntegrityError 
* Do some spot-checking and quality control on the groups and events. Some groups are not associated with Columbia, even though Facebook returns them in the search. Also some events and groups may be missing, as we do not do a comprehensive search for all Columbia groups.
    * Run groups scraper from different accounts by changing the email and password in groups_scraper.js
    * Manually add groups with group ID to pages_data.json and re-run the events scraper
* Instead of deleting old events, mark them as “expired” and save them as well as the users’ favorites. 
* Group id as a foreign key of events
    * To avoid the sql importing error  caused by the raw data because it’s possible the group_id of event is not included in group data.
